{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 08\n",
    "\n",
    "by Martin Hronec\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "0. [Advanced Pandas](#AdvPandas)\n",
    "1. [Merge, join and concatenate](#merge)\n",
    "2. [Reshaping](#reshape)\n",
    "3. [Split-apply-combine](#groupby)\n",
    "4. [Git collaboration](#gitco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1017: expected 21 fields, saw 22\\nSkipping line 2087: expected 21 fields, saw 22\\nSkipping line 2447: expected 21 fields, saw 22\\nSkipping line 2736: expected 21 fields, saw 22\\nSkipping line 2828: expected 21 fields, saw 23\\nSkipping line 3461: expected 21 fields, saw 24\\nSkipping line 3645: expected 21 fields, saw 24\\nSkipping line 4490: expected 21 fields, saw 23\\n'\n",
      "b'Skipping line 1816: expected 21 fields, saw 22\\nSkipping line 1877: expected 21 fields, saw 22\\nSkipping line 3253: expected 21 fields, saw 24\\nSkipping line 3270: expected 21 fields, saw 22\\nSkipping line 3329: expected 21 fields, saw 22\\n'\n",
      "b'Skipping line 7136: expected 21 fields, saw 23\\n'\n",
      "b'Skipping line 4890: expected 21 fields, saw 22\\nSkipping line 8304: expected 21 fields, saw 22\\nSkipping line 8358: expected 21 fields, saw 22\\n'\n",
      "b'Skipping line 1145: expected 21 fields, saw 22\\nSkipping line 1512: expected 21 fields, saw 22\\n'\n",
      "b'Skipping line 279: expected 21 fields, saw 22\\nSkipping line 4057: expected 21 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "# prepare empty dataframe that will be populated file-by-file\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "# columns will be czech, so let's rename them\n",
    "columns_translation = {'cislo_dot' : 'number',\n",
    "                    'kod_predm' : 'course_code',\n",
    "                    'nazev_predm' : 'course_title',\n",
    "                    'prednasejici' : 'teachers',\n",
    "                    'cvicici' : 'seminar_leaders',\n",
    "                    't1': 'c_value',\n",
    "                    't2': 'c_improve', \n",
    "                    'katedra_code' : 'department_code'}\n",
    "\n",
    "# data really start only in later years\n",
    "for d in os.listdir('unzipped_data/')[8:]:\n",
    "    try:\n",
    "        year, semester = d.split('_')[1], d.split('_')[2][:2]\n",
    "        df_temp = pd.read_csv('unzipped_data/' + d, sep = ';',\n",
    "                              header = 0, error_bad_lines=False)\n",
    "        df_temp = df_temp.rename(columns = columns_translation)\n",
    "        df_temp.dropna(how = 'all', inplace = True, axis = 1)\n",
    "        df_temp['year'] = int(year)\n",
    "        df_temp['semester'] = semester\n",
    "        df_all = df_all.reindex(df_temp.columns, axis = 1)\n",
    "        df_all = df_all.append(df_temp)\n",
    "        df_all.year = df_all.year.astype(int)\n",
    "    except:\n",
    "        print(d + ' has name not in the expected format.')\n",
    "        pass        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>course_code</th>\n",
       "      <th>course_title</th>\n",
       "      <th>teachers</th>\n",
       "      <th>seminar_leaders</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q3</th>\n",
       "      <th>q4</th>\n",
       "      <th>q5</th>\n",
       "      <th>...</th>\n",
       "      <th>q9</th>\n",
       "      <th>q10</th>\n",
       "      <th>q11</th>\n",
       "      <th>q12</th>\n",
       "      <th>q13</th>\n",
       "      <th>c_value</th>\n",
       "      <th>c_improve</th>\n",
       "      <th>department_code</th>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>JPM634</td>\n",
       "      <td>Crisis Games</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kučera,T.,Smetana,M.,Rychnovská,D.,Parízek, M.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Inovativnost vyuky, interaktivitu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kmv</td>\n",
       "      <td>2014</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>JEB111</td>\n",
       "      <td>Advanced Data Analysis in MS Excel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kraicová,L.,Polák,P.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ies</td>\n",
       "      <td>2014</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>JEB001</td>\n",
       "      <td>Bachelor´s Thesis Seminar I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cahlík,T.,Cotte,P.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Zajímavý hosté a zajímavá témata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ies</td>\n",
       "      <td>2014</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   number course_code                        course_title teachers  \\\n",
       "0     1.0      JPM634                        Crisis Games      NaN   \n",
       "1     2.0      JEB111  Advanced Data Analysis in MS Excel      NaN   \n",
       "2     3.0      JEB001         Bachelor´s Thesis Seminar I      NaN   \n",
       "\n",
       "                                  seminar_leaders   q1   q2  q3  q4  q5  \\\n",
       "0  Kučera,T.,Smetana,M.,Rychnovská,D.,Parízek, M.  5.0  3.0 NaN NaN NaN   \n",
       "1                            Kraicová,L.,Polák,P.  5.0  4.0 NaN NaN NaN   \n",
       "2                              Cahlík,T.,Cotte,P.  5.0  2.0 NaN NaN NaN   \n",
       "\n",
       "    ...      q9  q10  q11  q12  q13                            c_value  \\\n",
       "0   ...     1.0  5.0  5.0  5.0  5.0  Inovativnost vyuky, interaktivitu   \n",
       "1   ...     1.0  5.0  5.0  4.0  5.0                                NaN   \n",
       "2   ...     3.0  3.0  1.0  1.0  5.0   Zajímavý hosté a zajímavá témata   \n",
       "\n",
       "   c_improve  department_code  year semester  \n",
       "0        NaN              kmv  2014       ls  \n",
       "1        NaN              ies  2014       ls  \n",
       "2        NaN              ies  2014       ls  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_columns = [x for x in df_all.columns if 'q' in x]\n",
    "df_q = df_all[q_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using functions on pandas objects\n",
    "\n",
    "| Operation          | Function              |\n",
    "|--------------------|-----------------------|\n",
    "| Tablewise          | `pipe()`              |\n",
    "| Row or Column-wise | `apply()`             |\n",
    "| Aggregation        | `agg() / transform()` |\n",
    "| Elementwise        | `applymap()`          |\n",
    "\n",
    "**Tablewise**\n",
    "* DFs and Series can be arguments of the functions\n",
    "* if multiple functions need to be called in a sequence, use `pipe()` method, also called the method chaining\n",
    "    * often used in the data science setting\n",
    "    * inspired by unix pipes and dplyr (%>%) operator in R \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare some toy dataframe\n",
    "import statsmodels.formula.api as sm\n",
    "x = np.linspace(-10,10,100)\n",
    "y = x**2\n",
    "ols_data = pd.DataFrame({'x': x, 'y': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>  -0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>  -0.010</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>-1.542e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 10 Apr 2019</td> <th>  Prob (F-statistic):</th>   <td>  1.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:06:52</td>     <th>  Log-Likelihood:    </th>  <td> -483.38</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th>  <td>   970.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th>  <td>   976.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   34.0067</td> <td>    3.072</td> <td>   11.070</td> <td> 0.000</td> <td>   27.910</td> <td>   40.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>-9.437e-16</td> <td>    0.527</td> <td>-1.79e-15</td> <td> 1.000</td> <td>   -1.045</td> <td>    1.045</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.290</td> <th>  Durbin-Watson:     </th> <td>   0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>   9.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.638</td> <th>  Prob(JB):          </th> <td> 0.00721</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.140</td> <th>  Cond. No.          </th> <td>    5.83</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                      -0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.010\n",
       "Method:                 Least Squares   F-statistic:                -1.542e-14\n",
       "Date:                Wed, 10 Apr 2019   Prob (F-statistic):               1.00\n",
       "Time:                        15:06:52   Log-Likelihood:                -483.38\n",
       "No. Observations:                 100   AIC:                             970.8\n",
       "Df Residuals:                      98   BIC:                             976.0\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     34.0067      3.072     11.070      0.000      27.910      40.103\n",
       "x          -9.437e-16      0.527  -1.79e-15      1.000      -1.045       1.045\n",
       "==============================================================================\n",
       "Omnibus:                       14.290   Durbin-Watson:                   0.006\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):                9.864\n",
       "Skew:                           0.638   Prob(JB):                      0.00721\n",
       "Kurtosis:                       2.140   Cond. No.                         5.83\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method chaining way, with pipe(function, arguments)\n",
    "(ols_data.pipe((sm.ols, 'data'), 'y ~ x')\n",
    " .fit()\n",
    " .summary()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row or Column-wise Function Application\n",
    "* `apply()` is extremely powerful, when used with some brainpower*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2038"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_q.apply(np.mean, axis = 0)\n",
    "\n",
    "# using lambda\n",
    "df_q.apply(lambda x: (x - np.mean(x)) / np.std(x), axis = 0);\n",
    "\n",
    "# using custom function, with arguments (could have also be done with lambda)\n",
    "def add_and_substract(df, sub = 1, add = 1):\n",
    "    return df - sub + add\n",
    "df_q.apply(add_and_substract, args = (0,0));\n",
    "\n",
    "# A little bit more sophisticated:  e.g. get index of the observation with the longest value comment\n",
    "df_all['c_value'].apply(lambda x: len(str(x))).idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregation**\n",
    "* *`aggregate()`* and *`transform()`*\n",
    "* aggregation allows multiple aggregation operations in a single concise way\n",
    "* transformation method returns an object that is indexed the same as the original\n",
    "   * allows multiple operations at the same time, instead of one-by-one as `aggregate()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.156137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.071142</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            q1        q2        q3\n",
       "mean  4.156137       NaN       NaN\n",
       "std        NaN  1.071142       NaN\n",
       "var        NaN       NaN  0.977355"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregating simple function is the same as apply\n",
    "df_q.agg(np.mean, axis = 0)\n",
    "\n",
    "# aggregating more functions more interesting (you could do your own describe function easily! )\n",
    "df_q.aggregate([np.mean, np.std, np.min, np.max], axis = 0)\n",
    "\n",
    "# aggregating using dictionary, i.e. column specific aggregation\n",
    "df_q.agg({'q1' : [np.mean], 'q2': np.std, 'q3': np.var})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elementwise**\n",
    "* `applymap()`\n",
    "* not all functions can be vectorized ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some function\n",
    "def l(x):\n",
    "    return len(str(x))\n",
    "\n",
    "# for series\n",
    "df_all['c_value'].map(l);\n",
    "# for dataframe\n",
    "df_all[['c_value', 'c_improve']].applymap(l);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28704510421553514"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % of missing observations for specific column\n",
    "df_all['q5'].isnull().sum() / df_all['q1'].isnull().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge, join and concatenate\n",
    "\n",
    "## Concat\n",
    "* for combining together Series, DataFrame, and Panel objects with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations\n",
    "* concat() (and therefore append()) makes a full copy of the data\n",
    "    * constantly reusing this function can slow down performance\n",
    "\n",
    "## Join\n",
    "* in-memory join operations, similar to relational databases like SQL\n",
    "* you can see the comparison with SQL [here](http://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)\n",
    "\n",
    "\n",
    "## Merge\n",
    "* `merge()` serves as a starting point for all standard database join operations between DataFrame or named Series objects\n",
    "\n",
    "* `pd.merge()` is a function in the pandas namespace, and also a DataFrame instance method, with the calling DataFrame being implicitly considered the lef.t object in the join.\n",
    "\n",
    "* merge methods and (relational algebra)\n",
    "* care about merging repeatedly and _y in names \n",
    "\n",
    "## Join\n",
    "* uses merge internally for the index-on-index (by default) and column(s)-on-index join\n",
    "* DataFrame.join() is a convenient method for combining the columns of two potentially differently-indexed DataFrames into a single result DataFrame. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping and Pivot Tables\n",
    "* data is often stored in so-called “stacked” or “record” format, let's look at [pd documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html)\n",
    "\n",
    "* Pivoting pivot/pivot-tables\n",
    "* Stacking & unstacking\n",
    "* Melting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groub By: split-apply-combine\n",
    "\n",
    "* *Split* the data into groups\n",
    "* *Apply* a function to each group\n",
    "* *Combine* the results into a datastructure of our choosing\n",
    "\n",
    "\n",
    "* the split step is straightforward\n",
    "* in the apply step: we might wish to one of the following:\n",
    "\n",
    "    * Aggregation: compute a summary statistic (or statistics) for each group, e.g. (group means)\n",
    "    * Transformation: perform some group-specific computations and return a like-indexed object, e.g. (Z-score within a group)\n",
    "    * Filtration: discard some groups, according to a group-wise computation that evaluates True or False, e.g. discard data from groups with only a few members\n",
    "\n",
    "\n",
    "* name GroupBy should be quite familiar to you since you have used a SQL-based tools (or itertools), in which you can write code like:\n",
    "\n",
    "``SELECT Column1, Column2, mean(Column3), sum(Column4) \n",
    "\n",
    "FROM SomeTable\n",
    "\n",
    "GROUP BY Column1, Column2``\n",
    "\n",
    "## Splitting an object into groups\n",
    "\n",
    "* pandas objects can be split on any of their axes.\n",
    "* the abstract definition of grouping is to provide a mapping of labels to group names. (more on what the GroupBy object is later)\n",
    "* single group can be selected using `.get_group('label')`\n",
    "* use `.get_group()` example code\n",
    "\n",
    "* the mapping can be specified many different ways:\n",
    "    * a Python function, to be called on each of the axis labels.\n",
    "    * a list or NumPy array of the same length as the selected axis.\n",
    "    * a dict or Series, providing a label -> group name mapping.\n",
    "    * for DataFrame objects, a string indicating a column to be used to group\n",
    "        * `df.groupby('A')` is just syntactic sugar for `df.groupby(df['A'])`\n",
    "    * for DataFrame objects, a string indicating an index level to be used to group.\n",
    "    * a list of any of the above things.\n",
    "\n",
    "* On a DataFrame, we obtain a GroupBy object by calling groupby(). We could naturally group by either the A or B columns, or both\n",
    "* example of added functionality (If we also have a MultiIndex on columns A and B, we can group by all but the specified columns)\n",
    "    * `df.groupby(level=df2.index.names.difference(['B']))` \n",
    "\n",
    "* pd Index objects support duplicate values.\n",
    "    * if a non-unique index, all values for the same index will be in one group and thus the output of aggregation functions will only contain unique index values:\n",
    "\n",
    "* complicated data manipulations can be expressed in terms of GroupBy operations \n",
    "    * efficiency not guaranteed\n",
    "\n",
    "* by default the group keys are sorted during the groupby operation\n",
    "    * pass `sort=False` for potential speedups\n",
    "\n",
    "### GroupBy object attributes\n",
    "* the groups attribute is a dict whose keys are the computed unique groups and corresponding values being the axis labels belonging to each group.\n",
    "\n",
    "\n",
    "## Aggregating\n",
    "* once the GroupBy object has been created, several methods are available to perform a computation on the grouped data\n",
    "\n",
    "\n",
    "* the result of the aggregation will have the group names as the new index along the grouped axis\n",
    "* in the case of multiple keys $\\rightarrow$ the result is a MultiIndex by default, though this can be changed by using the as_index option:\n",
    "\n",
    "* Aggregating functions are the ones that reduce the dimension of the returned objects. Some common aggregating functions are tabulated below:\n",
    "`df.groupby('A').aggregate(np.sum)`\n",
    "\n",
    "* The aggregating functions above will exclude NA values. Any function which reduces a Series to a scalar value is an aggregation function and will work, a trivial example is df.groupby('A').agg(lambda ser: 1)\n",
    "    * aggregating multiple functions: pass a list/dict of functions to do aggregation\n",
    "    * the resulting aggregations are named for the functions themselves\n",
    "* By passing a dict to aggregate you can apply a different aggregation to the columns of a DataFrame\n",
    "`df.agg({'C': np.sum, 'D': lambda x: np.std(x, ddof=1)})`\n",
    "\n",
    "## Transformation \n",
    "\n",
    "* the `transform` method returns an object that is indexed the same (same size) as the one being grouped\n",
    "* suppose we wished to standardize the data within each group\n",
    "* the transform function must:\n",
    "    * return a result that is either the same size as the group chunk or broadcastable to the size of the group chunk (e.g., a scalar, `grouped.transform(lambda x: x.iloc[-1])`).\n",
    "    * operate column-by-column on the group chunk\n",
    "    * not perform in-place operations on the group chunk. Group chunks should be treated as immutable, and changes to a group chunk may produce unexpected results\n",
    "    * e.g. when using fillna, inplace must be False (grouped.transform(lambda x: x.fillna(inplace=False)))\n",
    "\n",
    "### expanding(), rolling()\n",
    "\n",
    "## Filtration\n",
    "\n",
    "* the filter methd returns a subset of the original object (only elements belonging to groups)\n",
    "    * alternatively, instead of dropping the offending groups, we can return a like-indexed objects where the groups that do not pass the filter are filled with NaNs.\n",
    "* for DataFrames with multiple columns, filters should explicitly specify a column as the filter criterion.\n",
    "\n",
    "## Flexible `appply`\n",
    "\n",
    "* some operations on the grouped data might not fit into either the aggregate or transform categories\n",
    "* can be substituted for both aggregate and transform in many standard use cases. However, apply can handle some exceptional use cases.\n",
    "\n",
    "* df.groupby('A').colname.std(). is more efficient than df.groupby('A').std().colname\n",
    "    * filtered before applying the aggregation function.\n",
    "\n",
    "\n",
    "## Groupby plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Date handling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
